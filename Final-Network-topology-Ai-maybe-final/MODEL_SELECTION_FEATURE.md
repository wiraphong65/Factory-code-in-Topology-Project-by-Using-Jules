# ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model LLM ‡πÉ‡∏ô AI Panel

## üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå

‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model LLM ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å Ollama ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÉ‡∏ô local ‡πÑ‡∏î‡πâ

## üöÄ ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤

### Backend (Python/FastAPI)
1. **API Endpoint ‡πÉ‡∏´‡∏°‡πà:**
   - `GET /ai/models` - ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ models ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Ollama
   - `POST /ai/set-model` - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

2. **OllamaService ‡πÉ‡∏´‡∏°‡πà:**
   - `get_available_models()` - ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ models ‡∏à‡∏≤‡∏Å Ollama v1 API
   - `set_model()` - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

### Frontend (React/TypeScript)
1. **AI Panel UI ‡πÉ‡∏´‡∏°‡πà:**
   - Dropdown ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model
   - ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ model ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
   - Loading state ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model

2. **API Integration:**
   - `aiAPI.getModels()` - ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ models
   - `aiAPI.setModel()` - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model

## üõ†Ô∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Ollama
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å https://ollama.ai

# ‡∏£‡∏±‡∏ô Ollama
ollama serve

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á models ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
ollama pull llama3.2
ollama pull deepseek-r1:14b
ollama pull mistral:latest
```

### 2. ‡∏£‡∏±‡∏ô Backend
```bash
cd backend
python run.py
```

### 3. ‡∏£‡∏±‡∏ô Frontend
```bash
npm run dev
```

### 4. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
```bash
python test_model_selection.py
```

## üì± ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

1. **‡πÄ‡∏õ‡∏¥‡∏î AI Panel** - ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô AI ‡πÉ‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô

2. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model** - ‡πÉ‡∏ä‡πâ dropdown "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AI Model" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

3. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞** - ‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ "Model ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô" ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á dropdown

4. **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"

## üîß ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤

### Backend Configuration (config.py)
```python
# Ollama Configuration
OLLAMA_BASE_URL: str = "http://localhost:11434"
OLLAMA_MODEL: str = "deepseek-r1:14b"  # model ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
OLLAMA_TIMEOUT: int = 30000000
```

### Frontend API (api.ts)
```typescript
// AI API endpoints
getModels: () => api.get('/ai/models'),
setModel: (data: { model: string }) => api.post('/ai/set-model', data),
```

## üéØ ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå

1. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡∏ô** - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
2. **‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô
3. **‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ** - UI ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
4. **Real-time** - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á restart

## üêõ ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô:

1. **Ollama ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠**
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà port 11434
   - ‡∏£‡∏±‡∏ô `ollama serve` ‡πÉ‡∏ô terminal

2. **‡πÑ‡∏°‡πà‡∏°‡∏µ Models**
   - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á models ‡∏î‡πâ‡∏ß‡∏¢ `ollama pull <model-name>`
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ `ollama list`

3. **Backend Error**
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs ‡πÉ‡∏ô terminal
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ database

## üìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

```typescript
// ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ models
const response = await aiAPI.getModels();
console.log(response.data.models); // ["llama3.2", "deepseek-r1:14b", ...]

// ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô model
await aiAPI.setModel({ model: "llama3.2" });
```

## üîÆ ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠

1. **Model Information** - ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ model
2. **Model Performance** - ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
3. **Custom Models** - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö custom models
4. **Model Presets** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ

---

‚ú® **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI ‡πÉ‡∏ô Network Topology ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô!**