#!/usr/bin/env python3
"""
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡πÉ‡∏ô AI Panel
"""

import asyncio
import aiohttp
import json

async def test_ollama_connection():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama"""
    try:
        async with aiohttp.ClientSession() as session:
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö health check
            async with session.get("http://localhost:11434/v1/models") as response:
                if response.status == 200:
                    data = await response.json()
                    print("‚úÖ Ollama ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    print(f"üìã Models ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà:")
                    for model in data.get("data", []):
                        print(f"  - {model.get('id', 'Unknown')}")
                    return True
                else:
                    print(f"‚ùå Ollama ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ (Status: {response.status})")
                    return False
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama: {e}")
        return False

async def test_backend_api():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Backend API"""
    try:
        async with aiohttp.ClientSession() as session:
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö health endpoint
            async with session.get("http://localhost:8000/") as response:
                if response.status == 200:
                    print("‚úÖ Backend API ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    return True
                else:
                    print(f"‚ùå Backend API ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ (Status: {response.status})")
                    return False
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Backend: {e}")
        return False

async def main():
    print("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model LLM")
    print("=" * 50)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Ollama
    print("\n1. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Ollama...")
    ollama_ok = await test_ollama_connection()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Backend
    print("\n2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Backend...")
    backend_ok = await test_backend_api()
    
    print("\n" + "=" * 50)
    if ollama_ok and backend_ok:
        print("‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
        print("\nüìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:")
        print("1. ‡πÄ‡∏õ‡∏¥‡∏î AI Panel")
        print("2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model ‡∏à‡∏≤‡∏Å dropdown")
        print("3. ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
    else:
        print("‚ùå ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        if not ollama_ok:
            print("  - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î Ollama ‡∏ó‡∏µ‡πà http://localhost:11434")
        if not backend_ok:
            print("  - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î Backend ‡∏ó‡∏µ‡πà http://localhost:8000")

if __name__ == "__main__":
    asyncio.run(main())